# Track Brief: Metric Definitions, Named Filters & Monitoring

> Generated by Architect based on Best Practice Alignment Plan (Part 1 + Part 6 + Part 7)

## What This Track Delivers
This track adds **metric definitions** and **named filters** to the YAML catalog (inspired by Snowflake Cortex Analyst's semantic view spec), implements key **pipeline fixes** (circuit breaker reset, cache threshold tuning, enum value injection), and establishes **monitoring tests** to track alignment with best practices over time.

### Three deliverables:
1. **Metric definitions** in `catalog/metrics.yaml` — pre-defined business calculations (e.g., "total PnL = SUM(instant_pnl)", "average edge = AVG(instant_edge) WHERE instant_edge != 0") that the agent can reference directly instead of inventing aggregations.
2. **Named filters** in `catalog/named_filters.yaml` — reusable filter patterns (e.g., "Mako trades only" = `portfolio NOT LIKE '%_CP'`, "options only" = `instrument_type IN ('option', 'future_option')`) that encode business logic the LLM frequently gets wrong.
3. **Pipeline fixes + monitoring:** Circuit breaker reset between questions, semantic cache threshold tuning (from 0.10 to configurable), enum value injection in prompts, and an alignment scorecard test suite.

## Source Requirements
- **Part 1 — Metric Definitions:**
  - Define 15-20 key metrics with name, formula, default_aggregation, required_dimensions
  - Examples: total_pnl, average_edge, volume_weighted_slippage, trade_count, fill_rate
  - Metrics reference enriched YAML columns (depends on Track 18 `category: measure` fields)
- **Part 1 — Named Filters:**
  - Define 10-15 reusable filters with name, sql_fragment, description
  - Examples: mako_trades_only, options_only, today, last_week, positive_edge, large_trades
  - Filters encode business logic that the LLM frequently hallucinates
- **Part 6 — Pipeline Fixes:**
  - Fix circuit breaker: reset `max_retries_reached` state on new question (callbacks.py)
  - Tune semantic cache: make cosine threshold configurable via Settings (default 0.10)
  - Enum value injection: include top categorical values in system prompt context
- **Part 7 — Alignment Scorecard:**
  - Test suite that measures: % columns with category, % columns with example_values, % tables with metrics, example coverage ratio, glossary concept count
  - Runs as part of `pytest` — warns (not fails) when below target thresholds

## Cross-Cutting Constraints
- **Depends on Track 18:** Metric definitions reference columns with `category: measure` and `typical_aggregation`
- **YAML format:** Metrics and filters use same YAML conventions as existing catalog (list of dicts with `name`, `description`, etc.)
- **Prompt integration:** `load_yaml_metadata` tool returns metrics/filters relevant to the queried tables
- **No breaking changes:** Circuit breaker fix and cache threshold change must not break existing tests

## Interface Contracts
- **Owned:**
  - `metric_definitions` — `catalog/metrics.yaml` with 15-20 business metric definitions
  - `named_filters` — `catalog/named_filters.yaml` with 10-15 reusable filter patterns
  - `monitoring_tests` — `tests/test_alignment_scorecard.py` with coverage metrics
- **Consumed:**
  - `enriched_yaml_schema` — Track 18's enriched YAML (category, typical_aggregation)
  - `yaml_catalog` — existing catalog loader infrastructure
  - `eval_runner` — eval framework for measuring impact of metrics/filters on accuracy

## Key Design Decisions
1. **Metrics as YAML, not code:** Metric definitions live in YAML alongside the catalog, not hardcoded in Python. The `load_yaml_metadata` tool includes relevant metrics in its output, giving the LLM explicit formulas to use.
2. **Named filters as SQL fragments:** Each filter has a `sql_fragment` field containing valid BigQuery WHERE clause text. The agent can insert these directly rather than inventing filter logic.
3. **Scorecard as warnings:** The alignment scorecard test suite uses `pytest.warns` / `warnings.warn`, not `assert`. It tracks progress toward best-practice alignment without blocking CI on aspirational targets.
4. **Configurable cache threshold:** Move the hardcoded 0.10 cosine distance threshold to `Settings.cache_similarity_threshold` with a sensible default. This enables tuning without code changes.

## Test Strategy
- **Unit:** Metric YAML validates against Pydantic schema (name, formula, default_aggregation required)
- **Unit:** Named filter SQL fragments are valid BigQuery syntax (dry-run test)
- **Unit:** Circuit breaker resets correctly between questions
- **Unit:** Cache threshold respects Settings value
- **Integration:** `load_yaml_metadata` returns relevant metrics for a KPI table query
- **Scorecard:** `test_alignment_scorecard.py` reports current coverage percentages

## Complexity: Medium
## Estimated Phases: 4
