<!-- generated by autopsy -->
# Scripts

## Purpose
Embedding pipeline tooling and local development startup scripts. run_embeddings.py creates BQ metadata infrastructure (datasets, tables, embeddings, vector indexes). populate_embeddings.py loads YAML catalog data into BQ. Shell scripts handle local ADK and LiteLLM proxy startup.

## Key Files
| File | Purpose | Key Exports |
|------|---------|-------------|
| run_embeddings.py | 7-step BQ embedding pipeline: create dataset/tables, populate, embed, index, test | `STEPS` dict, step functions |
| populate_embeddings.py | Load YAML catalog + examples into BQ column_embeddings and query_memory | `populate_column_embeddings`, `populate_query_memory` |
| start_local.sh | Local ADK startup with prerequisite checks (Python, gcloud, adk, .env, LiteLLM) | Shell script |
| start_litellm.sh | Local LiteLLM proxy startup, reads secrets from `pass` (GPG store) | Shell script |

## Data Flow
YAML catalog -> populate_embeddings.py -> BQ MERGE (column_embeddings, query_memory) -> run_embeddings.py -> ML.GENERATE_EMBEDDING -> VECTOR_SEARCH indexes

## Dependencies
- Internal: nl2sql_agent.config (Settings), nl2sql_agent.clients (LiveBigQueryClient), nl2sql_agent.catalog_loader
- External: BigQuery, Vertex AI (embedding model), `pass` (GPG password store for LiteLLM secrets)

## Patterns & Conventions
- All BQ operations use MERGE (idempotent), embeddings only generated WHERE ARRAY_LENGTH=0
- populate_embeddings.py batches rows (500 per batch) to stay under BQ 12MB query limit
- run_embeddings.py schema descriptions are hardcoded strings (not loaded from YAML)
- Shell scripts use prerequisite checks with colored output and fail-fast (set -euo pipefail)

## Gotchas
- populate_embeddings.py uses string interpolation for SQL STRUCT values (_escape_sql_string)
- run_embeddings.py routing rows use `ON FALSE` in MERGE (always insert, not idempotent for routing)
- run_embeddings.py has a cleanup step to deduplicate routing rows from previous runs
- start_litellm.sh reads real API keys from `pass` -- requires GPG key unlocked

## Testing
- Tests: tests/test_eval_runner.py covers some embedding pipeline logic indirectly
- Run: `python scripts/run_embeddings.py --step all`
- Gaps: No unit tests for populate_embeddings.py or run_embeddings.py functions

## Boundaries
- **Always:** use Settings for project/dataset refs, use MERGE for idempotency
- **Ask first:** changes to schema_embeddings descriptions or embedding model reference
- **Never:** run `--step create-tables` in prod without backup (it does CREATE OR REPLACE)

## Recent Changes
- 2026-02-20: Initial documentation generated by autopsy
