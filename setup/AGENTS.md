<!-- generated by autopsy -->
# Setup

## Purpose
Initial BigQuery dataset creation, table inventory documentation, data verification queries, and schema extraction tooling. These are one-time setup scripts that were already executed; kept for documentation and reproducibility.

## Key Files
| File | Purpose | Key Exports |
|------|---------|-------------|
| 01_create_datasets.sql | bq mk commands for nl2sql_omx_kpi and nl2sql_omx_data (already run) | - |
| 02_table_inventory.sql | Documents all 13 tables across both datasets with clustering info | - |
| 03_verify_data.sql | Row count verification, schema inspection, and sample value queries | - |
| extract_schemas.py | Extracts BQ table schemas to JSON files in schemas/ directory | `extract_schema` |

## Data Flow
BigQuery tables -> extract_schemas.py -> schemas/*.json (not committed, in .gitignore)

## Dependencies
- Internal: None (standalone scripts)
- External: google-cloud-bigquery, BigQuery ADC credentials

## Patterns & Conventions
- SQL files are marked "ALREADY EXECUTED -- DO NOT RUN AGAIN"
- extract_schemas.py hardcodes PROJECT = "cloud-data-n-base-d4b3" (not using settings)
- Output schemas/ directory is in .gitignore (regeneratable)

## Gotchas
- extract_schemas.py uses hardcoded project ID instead of settings -- inconsistent with rest of codebase
- 01_create_datasets.sql is just documentation of bq mk commands, not actual SQL
- Data is from 2026-02-17 only (single date partition)

## Testing
- No tests for setup scripts (one-time use)

## Boundaries
- **Always:** verify with 03_verify_data.sql after any schema changes
- **Ask first:** re-running extract_schemas.py (may overwrite intended changes)
- **Never:** re-run 01_create_datasets.sql against prod without confirming intent

## Recent Changes
- 2026-02-20: Initial documentation generated by autopsy
